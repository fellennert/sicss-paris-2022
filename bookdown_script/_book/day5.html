<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Day 5 Machine Learning | Course script for SICSS Paris</title>
  <meta name="description" content="This book serves as an accompanying script for the R sessions of the 2022 Summer Institute for Computational Social Science (SICSS), taking place at the Institut Polytechnique de Paris." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Day 5 Machine Learning | Course script for SICSS Paris" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This book serves as an accompanying script for the R sessions of the 2022 Summer Institute for Computational Social Science (SICSS), taking place at the Institut Polytechnique de Paris." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Day 5 Machine Learning | Course script for SICSS Paris" />
  
  <meta name="twitter:description" content="This book serves as an accompanying script for the R sessions of the 2022 Summer Institute for Computational Social Science (SICSS), taking place at the Institut Polytechnique de Paris." />
  

<meta name="author" content="Germain Gauthier" />
<meta name="author" content="Felix Lennert" />
<meta name="author" content="Étienne Ollion" />


<meta name="date" content="2022-06-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="day4.html"/>
<link rel="next" href="day6.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/vembedr-0.1.5/css/vembedr.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Script for SICSS-Paris 2022</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#outline"><i class="fa fa-check"></i><b>1.1</b> Outline</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#setup-procedure"><i class="fa fa-check"></i><b>1.2</b> Setup procedure</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#registration-for-api-usage"><i class="fa fa-check"></i><b>1.2.1</b> Registration for API usage</a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#docker-for-rselenium"><i class="fa fa-check"></i><b>1.2.2</b> Docker for <code>RSelenium</code></a></li>
<li class="chapter" data-level="1.2.3" data-path="index.html"><a href="index.html#some-useful-functions"><i class="fa fa-check"></i><b>1.2.3</b> Some useful functions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#further-links"><i class="fa fa-check"></i><b>1.3</b> Further links</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#last-but-not-least"><i class="fa fa-check"></i><b>1.4</b> Last but not least</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="day2.html"><a href="day2.html"><i class="fa fa-check"></i><b>2</b> Scraping the web</a>
<ul>
<li class="chapter" data-level="2.1" data-path="day2.html"><a href="day2.html#making-requests"><i class="fa fa-check"></i><b>2.1</b> Making requests</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="day2.html"><a href="day2.html#session"><i class="fa fa-check"></i><b>2.1.1</b> <code>session()</code></a></li>
<li class="chapter" data-level="2.1.2" data-path="day2.html"><a href="day2.html#forms"><i class="fa fa-check"></i><b>2.1.2</b> Forms</a></li>
<li class="chapter" data-level="2.1.3" data-path="day2.html"><a href="day2.html#scraping-hacks"><i class="fa fa-check"></i><b>2.1.3</b> Scraping hacks</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="day2.html"><a href="day2.html#application-programming-interfaces-apis"><i class="fa fa-check"></i><b>2.2</b> Application Programming Interfaces (APIs)</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="day2.html"><a href="day2.html#obtaining-their-data"><i class="fa fa-check"></i><b>2.2.1</b> Obtaining their data</a></li>
<li class="chapter" data-level="2.2.2" data-path="day2.html"><a href="day2.html#rtweet"><i class="fa fa-check"></i><b>2.2.2</b> <code>rtweet</code></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="day2.html"><a href="day2.html#further-links-1"><i class="fa fa-check"></i><b>2.3</b> Further links</a></li>
<li class="chapter" data-level="2.4" data-path="day2.html"><a href="day2.html#exercises"><i class="fa fa-check"></i><b>2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="day3.html"><a href="day3.html"><i class="fa fa-check"></i><b>3</b> Scraping the web – extracting data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="day3.html"><a href="day3.html#html-101"><i class="fa fa-check"></i><b>3.1</b> HTML 101</a></li>
<li class="chapter" data-level="3.2" data-path="day3.html"><a href="day3.html#extracting-content-in-rvest"><i class="fa fa-check"></i><b>3.2</b> Extracting content in <code>rvest</code></a></li>
<li class="chapter" data-level="3.3" data-path="day3.html"><a href="day3.html#scraping-html-pages-with-rvest"><i class="fa fa-check"></i><b>3.3</b> Scraping HTML pages with <code>rvest</code></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="day3.html"><a href="day3.html#html_text-and-html_text2"><i class="fa fa-check"></i><b>3.3.1</b> <code>html_text()</code> and <code>html_text2()</code></a></li>
<li class="chapter" data-level="3.3.2" data-path="day3.html"><a href="day3.html#extracting-tables"><i class="fa fa-check"></i><b>3.3.2</b> Extracting tables</a></li>
<li class="chapter" data-level="3.3.3" data-path="day3.html"><a href="day3.html#extracting-attributes"><i class="fa fa-check"></i><b>3.3.3</b> Extracting attributes</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="day3.html"><a href="day3.html#automating-scraping"><i class="fa fa-check"></i><b>3.4</b> Automating scraping</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="day3.html"><a href="day3.html#looping-over-pages"><i class="fa fa-check"></i><b>3.4.1</b> Looping over pages</a></li>
<li class="chapter" data-level="3.4.2" data-path="day3.html"><a href="day3.html#letting-the-scraper-navigate-on-its-own"><i class="fa fa-check"></i><b>3.4.2</b> Letting the scraper navigate on its own</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="day3.html"><a href="day3.html#conclusion"><i class="fa fa-check"></i><b>3.5</b> Conclusion</a></li>
<li class="chapter" data-level="3.6" data-path="day3.html"><a href="day3.html#further-links-2"><i class="fa fa-check"></i><b>3.6</b> Further links</a></li>
<li class="chapter" data-level="3.7" data-path="day3.html"><a href="day3.html#exercises-1"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="day4.html"><a href="day4.html"><i class="fa fa-check"></i><b>4</b> Text preprocessing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="day4.html"><a href="day4.html#basic-manipulations"><i class="fa fa-check"></i><b>4.1</b> Basic manipulations</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="day4.html"><a href="day4.html#changing-the-case-of-the-words"><i class="fa fa-check"></i><b>4.1.1</b> Changing the case of the words</a></li>
<li class="chapter" data-level="4.1.2" data-path="day4.html"><a href="day4.html#determining-a-strings-length"><i class="fa fa-check"></i><b>4.1.2</b> Determining a string’s length</a></li>
<li class="chapter" data-level="4.1.3" data-path="day4.html"><a href="day4.html#extracting-particular-characters"><i class="fa fa-check"></i><b>4.1.3</b> Extracting particular characters</a></li>
<li class="chapter" data-level="4.1.4" data-path="day4.html"><a href="day4.html#concatenating-strings"><i class="fa fa-check"></i><b>4.1.4</b> Concatenating strings</a></li>
<li class="chapter" data-level="4.1.5" data-path="day4.html"><a href="day4.html#repetition"><i class="fa fa-check"></i><b>4.1.5</b> Repetition</a></li>
<li class="chapter" data-level="4.1.6" data-path="day4.html"><a href="day4.html#removing-unnecessary-whitespaces"><i class="fa fa-check"></i><b>4.1.6</b> Removing unnecessary whitespaces</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="day4.html"><a href="day4.html#regular-expressions"><i class="fa fa-check"></i><b>4.2</b> Regular expressions</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="day4.html"><a href="day4.html#literal-characters"><i class="fa fa-check"></i><b>4.2.1</b> Literal characters</a></li>
<li class="chapter" data-level="4.2.2" data-path="day4.html"><a href="day4.html#metacharacters"><i class="fa fa-check"></i><b>4.2.2</b> Metacharacters</a></li>
<li class="chapter" data-level="4.2.3" data-path="day4.html"><a href="day4.html#sets-of-characters"><i class="fa fa-check"></i><b>4.2.3</b> Sets of characters</a></li>
<li class="chapter" data-level="4.2.4" data-path="day4.html"><a href="day4.html#anchors"><i class="fa fa-check"></i><b>4.2.4</b> Anchors</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="day4.html"><a href="day4.html#more-advanced-string-manipulation"><i class="fa fa-check"></i><b>4.3</b> More advanced string manipulation</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="day4.html"><a href="day4.html#detect-matches"><i class="fa fa-check"></i><b>4.3.1</b> Detect matches</a></li>
<li class="chapter" data-level="4.3.2" data-path="day4.html"><a href="day4.html#mutating-strings"><i class="fa fa-check"></i><b>4.3.2</b> Mutating strings</a></li>
<li class="chapter" data-level="4.3.3" data-path="day4.html"><a href="day4.html#extracting-text"><i class="fa fa-check"></i><b>4.3.3</b> Extracting text</a></li>
<li class="chapter" data-level="4.3.4" data-path="day4.html"><a href="day4.html#split-vectors"><i class="fa fa-check"></i><b>4.3.4</b> Split vectors</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="day4.html"><a href="day4.html#featurization-of-text"><i class="fa fa-check"></i><b>4.4</b> Featurization of text</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="day4.html"><a href="day4.html#pre-processing-with-tidytext"><i class="fa fa-check"></i><b>4.4.1</b> Pre-processing with <code>tidytext</code></a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="day4.html"><a href="day4.html#preprocessing-with-spacy"><i class="fa fa-check"></i><b>4.5</b> Preprocessing with <code>spaCy</code></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="day4.html"><a href="day4.html#initializing-spacy"><i class="fa fa-check"></i><b>4.5.1</b> Initializing spacy</a></li>
<li class="chapter" data-level="4.5.2" data-path="day4.html"><a href="day4.html#spacy_parse"><i class="fa fa-check"></i><b>4.5.2</b> <code>spacy_parse()</code></a></li>
<li class="chapter" data-level="4.5.3" data-path="day4.html"><a href="day4.html#pos-tags-ner-and-noun-phrases"><i class="fa fa-check"></i><b>4.5.3</b> POS tags, NER, and noun phrases</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="day4.html"><a href="day4.html#first-analyses"><i class="fa fa-check"></i><b>4.6</b> First analyses</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="day4.html"><a href="day4.html#counting-words-per-document"><i class="fa fa-check"></i><b>4.6.1</b> Counting words per document</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="day4.html"><a href="day4.html#converting-between-formats"><i class="fa fa-check"></i><b>4.7</b> Converting between formats</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="day4.html"><a href="day4.html#document-term-matrix"><i class="fa fa-check"></i><b>4.7.1</b> Document-term matrix</a></li>
<li class="chapter" data-level="4.7.2" data-path="day4.html"><a href="day4.html#document-feature-matrix"><i class="fa fa-check"></i><b>4.7.2</b> Document-feature matrix</a></li>
<li class="chapter" data-level="4.7.3" data-path="day4.html"><a href="day4.html#corpus-objects"><i class="fa fa-check"></i><b>4.7.3</b> Corpus objects</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="day4.html"><a href="day4.html#further-links-3"><i class="fa fa-check"></i><b>4.8</b> Further links</a></li>
<li class="chapter" data-level="4.9" data-path="day4.html"><a href="day4.html#exercises-2"><i class="fa fa-check"></i><b>4.9</b> Exercises</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="day4.html"><a href="day4.html#regexes"><i class="fa fa-check"></i><b>4.9.1</b> Regexes</a></li>
<li class="chapter" data-level="4.9.2" data-path="day4.html"><a href="day4.html#preprocessing"><i class="fa fa-check"></i><b>4.9.2</b> Preprocessing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="day5.html"><a href="day5.html"><i class="fa fa-check"></i><b>5</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="day5.html"><a href="day5.html#split-data"><i class="fa fa-check"></i><b>5.1</b> Split data</a></li>
<li class="chapter" data-level="5.2" data-path="day5.html"><a href="day5.html#pre-processing-and-featurization"><i class="fa fa-check"></i><b>5.2</b> Pre-processing and featurization</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="day5.html"><a href="day5.html#textrecipes-basic-example"><i class="fa fa-check"></i><b>5.2.1</b> <code>textrecipes</code> – basic example</a></li>
<li class="chapter" data-level="5.2.2" data-path="day5.html"><a href="day5.html#textrecipes-further-preprocessing-steps"><i class="fa fa-check"></i><b>5.2.2</b> <code>textrecipes</code> – further preprocessing steps</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="day5.html"><a href="day5.html#model-specification"><i class="fa fa-check"></i><b>5.3</b> Model specification</a></li>
<li class="chapter" data-level="5.4" data-path="day5.html"><a href="day5.html#model-training-workflows"><i class="fa fa-check"></i><b>5.4</b> Model training – <code>workflows</code></a></li>
<li class="chapter" data-level="5.5" data-path="day5.html"><a href="day5.html#model-evaluation"><i class="fa fa-check"></i><b>5.5</b> Model evaluation</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="day5.html"><a href="day5.html#hyperparameter-tuning"><i class="fa fa-check"></i><b>5.5.1</b> Hyperparameter tuning</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="day5.html"><a href="day5.html#final-fit"><i class="fa fa-check"></i><b>5.6</b> Final fit</a></li>
<li class="chapter" data-level="5.7" data-path="day5.html"><a href="day5.html#latent-dirichlet-allocation-lda"><i class="fa fa-check"></i><b>5.7</b> Latent Dirichlet Allocation (LDA)</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="day5.html"><a href="day5.html#document-term-matrix-1"><i class="fa fa-check"></i><b>5.7.1</b> Document-term matrix</a></li>
<li class="chapter" data-level="5.7.2" data-path="day5.html"><a href="day5.html#inferring-the-number-of-topics"><i class="fa fa-check"></i><b>5.7.2</b> Inferring the number of topics</a></li>
<li class="chapter" data-level="5.7.3" data-path="day5.html"><a href="day5.html#sense-making"><i class="fa fa-check"></i><b>5.7.3</b> Sense-making</a></li>
<li class="chapter" data-level="5.7.4" data-path="day5.html"><a href="day5.html#document-topic-probabilities"><i class="fa fa-check"></i><b>5.7.4</b> Document-topic probabilities</a></li>
<li class="chapter" data-level="5.7.5" data-path="day5.html"><a href="day5.html#structural-topic-models"><i class="fa fa-check"></i><b>5.7.5</b> Structural Topic Models</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="day5.html"><a href="day5.html#further-readings"><i class="fa fa-check"></i><b>5.8</b> Further readings</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="day6.html"><a href="day6.html"><i class="fa fa-check"></i><b>6</b> Word Embeddings</a></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Course script for SICSS Paris</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="day5" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Day 5</span> Machine Learning<a href="day5.html#day5" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In the following script, we will introduce you to the supervised and unsupervised classification of text. Supervised means that we will need to “show” the machine a data set that already contains the value or label we want to predict (the “dependent variable”) as well as all the variables that are used to predict the class/value (the independent variables or, in ML lingo, <em>features</em>). In the examples we will showcase, the features are the tokens that are contained in a document. Dependent variables are in our example sentiment.</p>
<p>Overall, the process of supervised classification using text in R encompasses the following steps:</p>
<ol style="list-style-type: decimal">
<li>Split data into training and test set</li>
<li>Pre-processing and featurization</li>
<li>Training</li>
<li>Evaluation and tuning (through cross-validation)
(… repeat 2.-4. as often as necessary)</li>
<li>Applying the model to the held-out test set</li>
<li>Final evaluation</li>
</ol>
<p>This is mirrored in the <code>workflow()</code> function from the <code>workflows</code> <span class="citation">(<a href="#ref-vaughan_workflows_2022" role="doc-biblioref">Vaughan 2022</a>)</span> package. There, you define the pre-processing procedure (<code>add_recipe()</code> – created through the <code>recipe()</code> function from the <code>recipes</code> <span class="citation">(<a href="#ref-kuhn_recipes_2022" role="doc-biblioref">Kuhn and Wickham 2022</a>)</span> and/or <code>textrecipes</code> <span class="citation">(<a href="#ref-hvitfeldt_textrecipes_2022" role="doc-biblioref">Hvitfeldt 2022</a>)</span> package(s)), the model specification with <code>add_spec()</code> – taking a model specification as created by the <code>parsnip</code> <span class="citation">(<a href="#ref-kuhn_parsnip_2022" role="doc-biblioref">Kuhn, Vaughan, and Hvitfeldt 2022</a>)</span> package.</p>
<div class="figure">
<img src="figures/workflow.png" alt="" />
<p class="caption">Workflow overview</p>
</div>
<p>In the next part, other approaches such as Support Vector Machines (SVM), penalized logistic regression models (penalized here means, loosely speaking, that insignificant predictors which contribute little will be shrunk and ignored – as the text contains many tokens that might not contribute much, those models lend themselves nicely to such tasks), random forest models, or XGBoost will be introduced. Those approaches are not to be explained in-depth, third-party articles will be linked though, but their intuition and the particularities of their implementation will be described. Since we use the <code>tidymodels</code> <span class="citation">(<a href="#ref-kuhn_tidymodels_2020" role="doc-biblioref">Kuhn and Wickham 2020</a>)</span> framework for implementation, trying out different approaches is straightforward. Also, the pre-processing differs, <code>recipes</code> and <code>textrecipes</code> facilitate this task decisively. Third, the evaluation of different classifiers will be described. Finally, the entire workflow will be demonstrated using the abortion Tweet data set.</p>
<div id="split-data" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Split data<a href="day5.html#split-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The example for today’s session is the IMDb data set. First, we load a whole bunch of packages and the data set.</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="day5.html#cb309-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb309-2"><a href="day5.html#cb309-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(textrecipes)</span>
<span id="cb309-3"><a href="day5.html#cb309-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(workflows)</span>
<span id="cb309-4"><a href="day5.html#cb309-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(discrim)</span>
<span id="cb309-5"><a href="day5.html#cb309-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb309-6"><a href="day5.html#cb309-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span>
<span id="cb309-7"><a href="day5.html#cb309-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb309-8"><a href="day5.html#cb309-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb309-9"><a href="day5.html#cb309-9" aria-hidden="true" tabindex="-1"></a>imdb_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;https://www.dropbox.com/s/0cfr4rkthtfryyp/imdb_reviews.csv?dl=1&quot;</span>)</span></code></pre></div>
<p>The first step is to divide the data into training and test sets using <code>initial_split()</code>. You need to make sure that the test and training set are fairly balanced which is achieved by using <code>strata =</code>. <code>prop =</code> refers to the proportion of rows that make it into the training set.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="day5.html#cb310-1" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(imdb_data, <span class="at">prop =</span> <span class="fl">0.8</span>, <span class="at">strata =</span> sentiment)</span>
<span id="cb310-2"><a href="day5.html#cb310-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb310-3"><a href="day5.html#cb310-3" aria-hidden="true" tabindex="-1"></a>imdb_train <span class="ot">&lt;-</span> <span class="fu">training</span>(split)</span>
<span id="cb310-4"><a href="day5.html#cb310-4" aria-hidden="true" tabindex="-1"></a>imdb_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(split)</span>
<span id="cb310-5"><a href="day5.html#cb310-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb310-6"><a href="day5.html#cb310-6" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(imdb_train)</span></code></pre></div>
<pre><code>## Rows: 20,000
## Columns: 2
## $ text      &lt;chr&gt; &quot;This is an example of why the majority of action films are …
## $ sentiment &lt;chr&gt; &quot;negative&quot;, &quot;negative&quot;, &quot;negative&quot;, &quot;negative&quot;, &quot;negative&quot;, …</code></pre>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="day5.html#cb312-1" aria-hidden="true" tabindex="-1"></a>imdb_train <span class="sc">%&gt;%</span> <span class="fu">count</span>(sentiment)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 2
##   sentiment     n
##   &lt;chr&gt;     &lt;int&gt;
## 1 negative  10000
## 2 positive  10000</code></pre>
</div>
<div id="pre-processing-and-featurization" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Pre-processing and featurization<a href="day5.html#pre-processing-and-featurization" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the <code>tidymodels</code> framework, pre-processing and featurization are performed through so-called <code>recipes</code>. For text data, so-called <code>textrecipes</code> are available.</p>
<div id="textrecipes-basic-example" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> <code>textrecipes</code> – basic example<a href="day5.html#textrecipes-basic-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the initial call, the formula needs to be provided. In our example, we want to predict the sentiment (“positive” or “negative”) using the text in the review. Then, different steps for pre-processing are added. Similar to what you have learned in the prior chapters containing measures based on the bag of words assumption, the first step is usually tokenization, achieved through <code>step_tokenize()</code>. In the end, the features need to be quantified, either through <code>step_tf()</code>, for raw term frequencies, or <code>step_tfidf()</code>, for TF-IDF. In between, various pre-processing steps such as word normalization (i.e., stemming or lemmatization), and removal of rare or common words Hence, a recipe for a very basic model just using raw frequencies and the 1,000 most common words would look as follows:</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="day5.html#cb314-1" aria-hidden="true" tabindex="-1"></a>imdb_basic_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(sentiment <span class="sc">~</span> text, <span class="at">data =</span> imdb_train) <span class="sc">%&gt;%</span> </span>
<span id="cb314-2"><a href="day5.html#cb314-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenize</span>(text) <span class="sc">%&gt;%</span> <span class="co"># tokenize text</span></span>
<span id="cb314-3"><a href="day5.html#cb314-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenfilter</span>(text, <span class="at">max_tokens =</span> <span class="dv">1000</span>) <span class="sc">%&gt;%</span> <span class="co"># only retain 1000 most common words</span></span>
<span id="cb314-4"><a href="day5.html#cb314-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># additional pre-processing steps can be added, see next chapter</span></span>
<span id="cb314-5"><a href="day5.html#cb314-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tf</span>(text) <span class="co"># final step: add term frequencies</span></span></code></pre></div>
<p>In case you want to know what the data set for the classification task looks like, you can <code>prep()</code> and finally <code>bake()</code> the recipe. Note that we need to specify the data set we want to pre-process in the recipe’s manner. In our case, we want to perform the operations on the data specified in the <code>basic_recipe</code> and, hence, need to specify <code>new_data = NULL</code>.</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="day5.html#cb315-1" aria-hidden="true" tabindex="-1"></a>imdb_basic_recipe <span class="sc">%&gt;%</span> </span>
<span id="cb315-2"><a href="day5.html#cb315-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb315-3"><a href="day5.html#cb315-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bake</span>(<span class="at">new_data =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<pre><code>## # A tibble: 20,000 × 1,001
##    sentiment tf_text_1 tf_text_10 tf_text_2 tf_text_20 tf_text_3 tf_text_4
##    &lt;fct&gt;         &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1 negative          0          1         0          0         0         1
##  2 negative          1          0         1          0         0         0
##  3 negative          0          0         0          0         1         0
##  4 negative          0          0         0          0         0         0
##  5 negative          0          0         0          0         0         0
##  6 negative          0          1         1          0         0         0
##  7 negative          0          0         0          0         0         0
##  8 negative          1          0         1          0         0         0
##  9 negative          0          0         0          0         0         0
## 10 negative          0          0         0          0         0         0
## # … with 19,990 more rows, and 994 more variables: tf_text_5 &lt;dbl&gt;,
## #   tf_text_7 &lt;dbl&gt;, tf_text_8 &lt;dbl&gt;, tf_text_80 &lt;dbl&gt;, tf_text_9 &lt;dbl&gt;,
## #   tf_text_a &lt;dbl&gt;, tf_text_able &lt;dbl&gt;, tf_text_about &lt;dbl&gt;,
## #   tf_text_above &lt;dbl&gt;, tf_text_absolutely &lt;dbl&gt;, tf_text_across &lt;dbl&gt;,
## #   tf_text_act &lt;dbl&gt;, tf_text_acted &lt;dbl&gt;, tf_text_acting &lt;dbl&gt;,
## #   tf_text_action &lt;dbl&gt;, tf_text_actor &lt;dbl&gt;, tf_text_actors &lt;dbl&gt;,
## #   tf_text_actress &lt;dbl&gt;, tf_text_actual &lt;dbl&gt;, tf_text_actually &lt;dbl&gt;, …</code></pre>
</div>
<div id="textrecipes-further-preprocessing-steps" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> <code>textrecipes</code> – further preprocessing steps<a href="day5.html#textrecipes-further-preprocessing-steps" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>More steps exist. These always follow the same structure: their first two arguments are the recipe (which in practice does not matter, because they are generally used in a “pipeline”) and the variable that is affected (in our example “text” because it is the one to be modified). The rest of the arguments depends on the function. In the following, we will briefly list them and their most important arguments. Find the exhaustive list <a href="https://cran.r-project.org/web/packages/textrecipes/textrecipes.pdf">here</a>,</p>
<ul>
<li><code>step_tokenfilter()</code>: filters tokens
<ul>
<li><code>max_times =</code> upper threshold for how often a term can appear (removes common words)</li>
<li><code>min_times =</code> lower threshold for how often a term can appear (removes rare words)</li>
<li><code>max_tokens =</code> maximum number of tokens to be retained; will only keep the ones that appear the most often</li>
<li>you should filter before using <code>step_tf</code> or <code>step_tfidf</code> to limit the number of variables that are created</li>
</ul></li>
<li><code>step_lemma()</code>: allows you to extract the lemma
<ul>
<li>in case you want to use it, make sure you tokenize via <code>spacyr</code> (by using <code>step_tokenize(text, engine = "spacyr"))</code></li>
</ul></li>
<li><code>step_pos_filter()</code>: adds the Part-of-speech tags
<ul>
<li><code>keep_tags =</code> character vector that specifies the types of tags to retain (default is “NOUN”, for more details see <a href="https://github.com/explosion/spaCy/blob/master/spacy/glossary.py">here</a> or consult chapter <a href="day4.html#day4">4</a>)</li>
<li>in case you want to use it, make sure you tokenize via <code>spacyr</code> (by using <code>step_tokenize(text, engine = "spacyr"))</code></li>
</ul></li>
<li><code>step_stem()</code>: stems tokens
<ul>
<li><code>custom_stem =</code> specifies the stemming function. Defaults to <code>SnowballC</code>. Custom functions can be provided.</li>
<li><code>options =</code> can be used to provide arguments (stored as named elements of a list) to the stemming function. E.g., <code>step_stem(text, custom_stem = "SnowballC", options = list(language = "russian"))</code></li>
</ul></li>
<li><code>step_stopwords()</code>: removes stopwords
<ul>
<li><code>source =</code> alternative stopword lists can be used; potential values are contained in <code>stopwords::stopwords_getsources()</code></li>
<li><code>custom_stopword_source =</code> provide your own stopword list</li>
<li><code>language =</code> specify language of stop word list; potential values can be found in <code>stopwords::stopwords_getlanguages()</code></li>
</ul></li>
<li><code>step_ngram()</code>: takes into account order of terms, provides more context
<ul>
<li><code>num_tokens =</code> number of tokens in n-gram – defaults to 3 – trigrams</li>
<li><code>min_num_tokens =</code> minimal number of tokens in n-gram – <code>step_ngram(text, num_tokens = 3, min_num_tokens = 1)</code> will return all uni-, bi-, and trigrams.</li>
</ul></li>
<li><code>step_word_embeddings()</code>: use pre-trained embeddings for words
<ul>
<li><code>embeddings()</code>: tibble of pre-trained embeddings</li>
</ul></li>
<li><code>step_normalize()</code>: performs unicode normalization as a preprocessing step
<ul>
<li><code>normalization_form =</code> which Unicode Normalization to use, overview in <a href="https://www.rdocumentation.org/packages/stringi/versions/1.7.6/topics/stri_trans_nfc"><code>stringi::stri_trans_nfc()</code></a></li>
</ul></li>
<li><code>themis::step_upsample()</code> takes care of unbalanced dependent variables (which need to be specified in the call)
<ul>
<li><code>over_ratio =</code> ratio of desired minority-to-minority frequencies</li>
</ul></li>
</ul>
</div>
</div>
<div id="model-specification" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Model specification<a href="day5.html#model-specification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that the data is ready, the model can be specified. The <code>parsnip</code> package is used for this. It contains a model specification, the type, and the engine. For Naïve Bayes, this would look like the following (note that you will need to install the relevant packages – here: <code>discrim</code> – before using them):</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="day5.html#cb317-1" aria-hidden="true" tabindex="-1"></a>nb_spec <span class="ot">&lt;-</span> <span class="fu">naive_Bayes</span>() <span class="sc">%&gt;%</span> <span class="co"># the initial function, coming from the parsnip package</span></span>
<span id="cb317-2"><a href="day5.html#cb317-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="sc">%&gt;%</span> <span class="co"># classification for discrete values, regression for continuous ones</span></span>
<span id="cb317-3"><a href="day5.html#cb317-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;naivebayes&quot;</span>) <span class="co"># needs to be installed</span></span></code></pre></div>
<p>Other model specifications you might deem relevant:</p>
<ul>
<li>Logistic regression</li>
</ul>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="day5.html#cb318-1" aria-hidden="true" tabindex="-1"></a>lr_spec <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb318-2"><a href="day5.html#cb318-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glm&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb318-3"><a href="day5.html#cb318-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span></code></pre></div>
<ul>
<li>Logistic regression (penalized with Lasso):</li>
</ul>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="day5.html#cb319-1" aria-hidden="true" tabindex="-1"></a>lasso_spec <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">mixture =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb319-2"><a href="day5.html#cb319-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glm&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb319-3"><a href="day5.html#cb319-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) </span></code></pre></div>
<ul>
<li>SVM (here, <code>step_normalize(all_predictors())</code> needs to be the last step in the recipe)</li>
</ul>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="day5.html#cb320-1" aria-hidden="true" tabindex="-1"></a>svm_spec <span class="ot">&lt;-</span> <span class="fu">svm_linear</span>() <span class="sc">%&gt;%</span></span>
<span id="cb320-2"><a href="day5.html#cb320-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> <span class="co"># can also be &quot;classification&quot;</span></span>
<span id="cb320-3"><a href="day5.html#cb320-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;LiblineaR&quot;</span>)</span></code></pre></div>
<ul>
<li>Random Forest (with 1000 decision trees):</li>
</ul>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="day5.html#cb321-1" aria-hidden="true" tabindex="-1"></a>rf_spec <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">trees =</span> <span class="dv">1000</span>) <span class="sc">%&gt;%</span></span>
<span id="cb321-2"><a href="day5.html#cb321-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb321-3"><a href="day5.html#cb321-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="co"># can also be &quot;classification&quot;</span></span></code></pre></div>
<ul>
<li>xgBoost (with 20 decision trees):</li>
</ul>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="day5.html#cb322-1" aria-hidden="true" tabindex="-1"></a>xg_spec <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(<span class="at">trees =</span> <span class="dv">20</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb322-2"><a href="day5.html#cb322-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;xgboost&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb322-3"><a href="day5.html#cb322-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="co"># can also be classification</span></span></code></pre></div>
</div>
<div id="model-training-workflows" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Model training – <code>workflows</code><a href="day5.html#model-training-workflows" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A workflow can be defined to train the model. It will contain the recipe, hence taking care of the pre-processing, and the model specification. In the end, it can be used to fit the model.</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="day5.html#cb323-1" aria-hidden="true" tabindex="-1"></a>imdb_nb_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb323-2"><a href="day5.html#cb323-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(imdb_basic_recipe) <span class="sc">%&gt;%</span> </span>
<span id="cb323-3"><a href="day5.html#cb323-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(nb_spec)</span></code></pre></div>
<p>It can then be fit using <code>fit()</code>.</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="day5.html#cb324-1" aria-hidden="true" tabindex="-1"></a>imdb_nb_basic <span class="ot">&lt;-</span> imdb_nb_wf <span class="sc">%&gt;%</span> <span class="fu">fit</span>(<span class="at">data =</span> imdb_train)</span></code></pre></div>
</div>
<div id="model-evaluation" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Model evaluation<a href="day5.html#model-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that a first model has been trained, its performance can be evaluated. In theory, we have a test set for this. However, the test set is precious and should only be used once we are sure that we have found a good model. Hence, for these intermediary tuning steps, we need to come up with another solution. So-called cross-validation lends itself nicely to this task. The rationale behind it is that chunks from the training set are used as test sets. So, in the case of 10-fold cross-validation, the test set is divided into 10 distinctive chunks of data. Then, 10 models are trained on the respective 9/10 of the training set that is not used for evaluation. Finally, each model is evaluated against the respective held-out “test set” and the performance metrics averaged.</p>
<div class="figure">
<img src="https://scikit-learn.org/stable/_images/grid_search_cross_validation.png" alt="" />
<p class="caption">Graph taken from <a href="https://scikit-learn.org/stable/modules/cross_validation.html/" class="uri">https://scikit-learn.org/stable/modules/cross_validation.html/</a></p>
</div>
<p>First, the folds need to be determined. we set a seed in the beginning to ensure reproducibility.</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="day5.html#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tune)</span>
<span id="cb325-2"><a href="day5.html#cb325-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb325-3"><a href="day5.html#cb325-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb325-4"><a href="day5.html#cb325-4" aria-hidden="true" tabindex="-1"></a>imdb_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(imdb_train)</span></code></pre></div>
<p><code>fit_resamples()</code> trains models on the respective samples. (Note that for this to work, no model must have been fit to this workflow before. Hence, you either need to define a new workflow first or restart the session and skip the fit-line from before.)</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="day5.html#cb326-1" aria-hidden="true" tabindex="-1"></a>imdb_nb_resampled <span class="ot">&lt;-</span> <span class="fu">fit_resamples</span>(</span>
<span id="cb326-2"><a href="day5.html#cb326-2" aria-hidden="true" tabindex="-1"></a>  imdb_nb_wf,</span>
<span id="cb326-3"><a href="day5.html#cb326-3" aria-hidden="true" tabindex="-1"></a>  imdb_folds,</span>
<span id="cb326-4"><a href="day5.html#cb326-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">control_resamples</span>(<span class="at">save_pred =</span> <span class="cn">TRUE</span>),</span>
<span id="cb326-5"><a href="day5.html#cb326-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(accuracy, recall, precision)</span>
<span id="cb326-6"><a href="day5.html#cb326-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><code>collect_metrics()</code> can be used to evaluate the results.</p>
<ul>
<li>Accuracy tells me the share of correct predictions overall</li>
<li>Precision tells me the number of correct positive predictions</li>
<li>Recall tells me how many actual positives are predicted properly</li>
</ul>
<p>In all cases, values close to 1 are better.</p>
<p><code>collect_predictions()</code> will give you the predicted values.</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="day5.html#cb327-1" aria-hidden="true" tabindex="-1"></a>nb_rs_metrics <span class="ot">&lt;-</span> <span class="fu">collect_metrics</span>(imdb_nb_resampled)</span>
<span id="cb327-2"><a href="day5.html#cb327-2" aria-hidden="true" tabindex="-1"></a>nb_rs_predictions <span class="ot">&lt;-</span> <span class="fu">collect_predictions</span>(imdb_nb_resampled)</span></code></pre></div>
<p>This can also be used to create the confusion matrix by hand.</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="day5.html#cb328-1" aria-hidden="true" tabindex="-1"></a>confusion_mat <span class="ot">&lt;-</span> nb_rs_predictions <span class="sc">%&gt;%</span> </span>
<span id="cb328-2"><a href="day5.html#cb328-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(id) <span class="sc">%&gt;%</span> </span>
<span id="cb328-3"><a href="day5.html#cb328-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">confusion_class =</span> <span class="fu">case_when</span>(.pred_class <span class="sc">==</span> <span class="st">&quot;positive&quot;</span> <span class="sc">&amp;</span> sentiment <span class="sc">==</span> <span class="st">&quot;positive&quot;</span> <span class="sc">~</span> <span class="st">&quot;TP&quot;</span>,</span>
<span id="cb328-4"><a href="day5.html#cb328-4" aria-hidden="true" tabindex="-1"></a>                                     .pred_class <span class="sc">==</span> <span class="st">&quot;positive&quot;</span> <span class="sc">&amp;</span> sentiment <span class="sc">==</span> <span class="st">&quot;negative&quot;</span> <span class="sc">~</span> <span class="st">&quot;FP&quot;</span>,</span>
<span id="cb328-5"><a href="day5.html#cb328-5" aria-hidden="true" tabindex="-1"></a>                                     .pred_class <span class="sc">==</span> <span class="st">&quot;negative&quot;</span> <span class="sc">&amp;</span> sentiment <span class="sc">==</span> <span class="st">&quot;negative&quot;</span> <span class="sc">~</span> <span class="st">&quot;TN&quot;</span>,</span>
<span id="cb328-6"><a href="day5.html#cb328-6" aria-hidden="true" tabindex="-1"></a>                                     .pred_class <span class="sc">==</span> <span class="st">&quot;negative&quot;</span> <span class="sc">&amp;</span> sentiment <span class="sc">==</span> <span class="st">&quot;positive&quot;</span> <span class="sc">~</span> <span class="st">&quot;FN&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb328-7"><a href="day5.html#cb328-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(confusion_class) <span class="sc">%&gt;%</span> </span>
<span id="cb328-8"><a href="day5.html#cb328-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb328-9"><a href="day5.html#cb328-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> confusion_class, <span class="at">values_from =</span> n)</span></code></pre></div>
<p>Now you can go back and adapt the pre-processing recipe, fit a new model, or try a different classifier, and evaluate it against the same set of folds. Once you are satisfied, you can proceed to check the workflow on the held-out test data.</p>
<div id="hyperparameter-tuning" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Hyperparameter tuning<a href="day5.html#hyperparameter-tuning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Some models also require the tuning of hyperparameters (for instance, lasso regression). If we wanted to tune these values, we could do so using the <code>tune</code> package. There, the parameter that needs to be tuned gets a placeholder in the model specification. Through variation of the placeholder, the optimal solution can be empirically determined.</p>
<p>So, in the first example, we will try to determine a good penalty value for LASSO regression.</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="day5.html#cb329-1" aria-hidden="true" tabindex="-1"></a>lasso_tune_spec <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>(<span class="at">penalty =</span> <span class="fu">tune</span>(), <span class="at">mixture =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb329-2"><a href="day5.html#cb329-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb329-3"><a href="day5.html#cb329-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glmnet&quot;</span>)</span></code></pre></div>
<p>we will also play with the numbers of tokens to be included:</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="day5.html#cb330-1" aria-hidden="true" tabindex="-1"></a>imdb_tune_basic_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(sentiment <span class="sc">~</span> text, <span class="at">data =</span> imdb_train) <span class="sc">%&gt;%</span> </span>
<span id="cb330-2"><a href="day5.html#cb330-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenize</span>(text) <span class="sc">%&gt;%</span></span>
<span id="cb330-3"><a href="day5.html#cb330-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tokenfilter</span>(text, <span class="at">max_tokens =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb330-4"><a href="day5.html#cb330-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_tf</span>(text)</span></code></pre></div>
<p>The <code>dials</code> <span class="citation">(<a href="#ref-kuhn_dials_2022" role="doc-biblioref">Kuhn and Frick 2022</a>)</span> package provides the handy <code>grid_regular()</code> function which chooses suitable values for certain parameters.</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="day5.html#cb331-1" aria-hidden="true" tabindex="-1"></a>lambda_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(</span>
<span id="cb331-2"><a href="day5.html#cb331-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">penalty</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">0</span>)), </span>
<span id="cb331-3"><a href="day5.html#cb331-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">max_tokens</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="fl">1e3</span>, <span class="fl">2e3</span>)),</span>
<span id="cb331-4"><a href="day5.html#cb331-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">levels =</span> <span class="fu">c</span>(<span class="at">penalty =</span> <span class="dv">3</span>, <span class="at">max_tokens =</span> <span class="dv">2</span>)</span>
<span id="cb331-5"><a href="day5.html#cb331-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Then, we need to define a new workflow, too.</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="day5.html#cb332-1" aria-hidden="true" tabindex="-1"></a>lasso_tune_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb332-2"><a href="day5.html#cb332-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(imdb_tune_basic_recipe) <span class="sc">%&gt;%</span></span>
<span id="cb332-3"><a href="day5.html#cb332-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(lasso_tune_spec)</span></code></pre></div>
<p>For the resampling, we can use tune_grid() which will use the workflow, a set of folds (we use the ones we created earlier), and a grid containing the different parameters.</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="day5.html#cb333-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb333-2"><a href="day5.html#cb333-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-3"><a href="day5.html#cb333-3" aria-hidden="true" tabindex="-1"></a>tune_lasso_rs <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb333-4"><a href="day5.html#cb333-4" aria-hidden="true" tabindex="-1"></a>  lasso_tune_wf,</span>
<span id="cb333-5"><a href="day5.html#cb333-5" aria-hidden="true" tabindex="-1"></a>  imdb_folds,</span>
<span id="cb333-6"><a href="day5.html#cb333-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> lambda_grid,</span>
<span id="cb333-7"><a href="day5.html#cb333-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(accuracy, sensitivity, specificity)</span>
<span id="cb333-8"><a href="day5.html#cb333-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Again, we can access the resulting metrics using <code>collect_metrics()</code>:</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="day5.html#cb334-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(tune_lasso_rs)</span></code></pre></div>
<pre><code>## # A tibble: 18 × 8
##    penalty max_tokens .metric     .estimator  mean     n std_err .config        
##      &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          
##  1  0.0001       1000 accuracy    binary     0.864    10 0.00433 Preprocessor1_…
##  2  0.0001       1000 sensitivity binary     0.858    10 0.00537 Preprocessor1_…
##  3  0.0001       1000 specificity binary     0.869    10 0.00441 Preprocessor1_…
##  4  0.01         1000 accuracy    binary     0.851    10 0.00329 Preprocessor1_…
##  5  0.01         1000 sensitivity binary     0.814    10 0.00556 Preprocessor1_…
##  6  0.01         1000 specificity binary     0.887    10 0.00298 Preprocessor1_…
##  7  1            1000 accuracy    binary     0.491    10 0.00240 Preprocessor1_…
##  8  1            1000 sensitivity binary     0.6      10 0.163   Preprocessor1_…
##  9  1            1000 specificity binary     0.4      10 0.163   Preprocessor1_…
## 10  0.0001       2000 accuracy    binary     0.864    10 0.00254 Preprocessor2_…
## 11  0.0001       2000 sensitivity binary     0.860    10 0.00439 Preprocessor2_…
## 12  0.0001       2000 specificity binary     0.867    10 0.00267 Preprocessor2_…
## 13  0.01         2000 accuracy    binary     0.858    10 0.00273 Preprocessor2_…
## 14  0.01         2000 sensitivity binary     0.823    10 0.00542 Preprocessor2_…
## 15  0.01         2000 specificity binary     0.893    10 0.00332 Preprocessor2_…
## 16  1            2000 accuracy    binary     0.491    10 0.00240 Preprocessor2_…
## 17  1            2000 sensitivity binary     0.6      10 0.163   Preprocessor2_…
## 18  1            2000 specificity binary     0.4      10 0.163   Preprocessor2_…</code></pre>
<p><code>autoplot()</code> can be used to visualize them:</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="day5.html#cb336-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tune_lasso_rs) <span class="sc">+</span></span>
<span id="cb336-2"><a href="day5.html#cb336-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb336-3"><a href="day5.html#cb336-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Lasso model performance across 3 regularization penalties&quot;</span></span>
<span id="cb336-4"><a href="day5.html#cb336-4" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-185-1.png" width="672" /></p>
<p>Also, we can use <code>show_best()</code> to look at the best result. Subsequently, <code>select_best()</code> allows me to choose it. In real life, we would choose the best trade-off between a model as simple and as good as possible. Using <code>select_by_pct_loss()</code>, we choose the one that performs still more or less on par with the best option (i.e., within 2 percent accuracy) but is considerably simpler. Finally, once we are satisfied with the outcome, we can <code>finalize_workflow()</code> and fit the final model to the test data.</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="day5.html#cb337-1" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(tune_lasso_rs, <span class="st">&quot;accuracy&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 5 × 8
##   penalty max_tokens .metric  .estimator  mean     n std_err .config            
##     &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;              
## 1  0.0001       1000 accuracy binary     0.864    10 0.00433 Preprocessor1_Mode…
## 2  0.0001       2000 accuracy binary     0.864    10 0.00254 Preprocessor2_Mode…
## 3  0.01         2000 accuracy binary     0.858    10 0.00273 Preprocessor2_Mode…
## 4  0.01         1000 accuracy binary     0.851    10 0.00329 Preprocessor1_Mode…
## 5  1            1000 accuracy binary     0.491    10 0.00240 Preprocessor1_Mode…</code></pre>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="day5.html#cb339-1" aria-hidden="true" tabindex="-1"></a>final_lasso_imdb <span class="ot">&lt;-</span> <span class="fu">finalize_workflow</span>(lasso_tune_wf, <span class="fu">select_by_pct_loss</span>(tune_lasso_rs, <span class="at">metric =</span> <span class="st">&quot;accuracy&quot;</span>, <span class="sc">-</span>penalty))</span></code></pre></div>
</div>
</div>
<div id="final-fit" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Final fit<a href="day5.html#final-fit" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now we can finally fit our model to the training data and predict on the test data. <code>last_fit()</code> is the way to go. It takes the workflow and the split (as defined by <code>initial_split()</code>) as parameters.</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="day5.html#cb340-1" aria-hidden="true" tabindex="-1"></a>final_fitted <span class="ot">&lt;-</span> <span class="fu">last_fit</span>(final_lasso_imdb, split)</span>
<span id="cb340-2"><a href="day5.html#cb340-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-3"><a href="day5.html#cb340-3" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(final_fitted)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
##   .metric  .estimator .estimate .config             
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary         0.855 Preprocessor1_Model1
## 2 roc_auc  binary         0.927 Preprocessor1_Model1</code></pre>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="day5.html#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_predictions</span>(final_fitted) <span class="sc">%&gt;%</span></span>
<span id="cb342-2"><a href="day5.html#cb342-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> sentiment, <span class="at">estimate =</span> .pred_class) <span class="sc">%&gt;%</span></span>
<span id="cb342-3"><a href="day5.html#cb342-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(<span class="at">type =</span> <span class="st">&quot;heatmap&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-187-1.png" width="672" /></p>
</div>
<div id="latent-dirichlet-allocation-lda" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Latent Dirichlet Allocation (LDA)<a href="day5.html#latent-dirichlet-allocation-lda" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the former section, I, first, explored how the sentiment in the SOTU addresses has evolved over the 20th century. Then, we looked at the decade-specific vocabulary. This, paired with previous knowledge of what happened throughout the 20th century, sufficed to gain some sort of insight. However, another approach to infer meaning from text is to search it for topics. This is also possible with the SOTU corpus which we have at hand.</p>
<p>The two main assumptions of LDA are as follows:</p>
<ul>
<li>Every document is a mixture of topics.</li>
<li>Every topic is a mixture of words.</li>
</ul>
<p>Hence, singular documents do not necessarily be distinct in terms of their content. They can be related – if they contain the same topics. This is more in line with natural language use.</p>
<p>The following graphic depicts a flowchart of text analysis with the <code>tidytext</code> package.</p>
<div class="figure">
<img src="https://www.tidytextmining.com/images/tmwr_0601.png" alt="" />
<p class="caption">Text analysis flowchart</p>
</div>
<p>What becomes evident is that the actual topic modeling does not happen within <code>tidytext</code>. For this, the text needs to be transformed into a document-term-matrix and then passed on to the <code>topicmodels</code> package <span class="citation">(<a href="#ref-grun_topicmodels_2020" role="doc-biblioref">Grün et al. 2020</a>)</span>, which will take care of the modeling process. Thereafter, the results are turned back into a tidy format, using <code>broom</code> so that they can be visualized using <code>ggplot2</code>.</p>
<div id="document-term-matrix-1" class="section level3 hasAnchor" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Document-term matrix<a href="day5.html#document-term-matrix-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To search for the topics which are prevalent in the singular addresses through LDA, we need to transform the tidy tibble into a document-term matrix first. This can be achieved with <code>cast_dtm()</code>.</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="day5.html#cb343-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sotu)</span>
<span id="cb343-2"><a href="day5.html#cb343-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span>
<span id="cb343-3"><a href="day5.html#cb343-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(SnowballC)</span>
<span id="cb343-4"><a href="day5.html#cb343-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb343-5"><a href="day5.html#cb343-5" aria-hidden="true" tabindex="-1"></a>sotu_clean <span class="ot">&lt;-</span> sotu_meta <span class="sc">%&gt;%</span> </span>
<span id="cb343-6"><a href="day5.html#cb343-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">text =</span> sotu_text <span class="sc">%&gt;%</span> </span>
<span id="cb343-7"><a href="day5.html#cb343-7" aria-hidden="true" tabindex="-1"></a>           <span class="fu">str_replace_all</span>(<span class="st">&quot;[,.]&quot;</span>, <span class="st">&quot; &quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb343-8"><a href="day5.html#cb343-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">between</span>(year, <span class="dv">1900</span>, <span class="dv">2000</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb343-9"><a href="day5.html#cb343-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(<span class="at">output =</span> token, <span class="at">input =</span> text) <span class="sc">%&gt;%</span> </span>
<span id="cb343-10"><a href="day5.html#cb343-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">anti_join</span>(<span class="fu">get_stopwords</span>(), <span class="at">by =</span> <span class="fu">c</span>(<span class="st">&quot;token&quot;</span> <span class="ot">=</span> <span class="st">&quot;word&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb343-11"><a href="day5.html#cb343-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">str_detect</span>(token, <span class="st">&quot;[:digit:]&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb343-12"><a href="day5.html#cb343-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">token =</span> <span class="fu">wordStem</span>(token, <span class="at">language =</span> <span class="st">&quot;en&quot;</span>))</span>
<span id="cb343-13"><a href="day5.html#cb343-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb343-14"><a href="day5.html#cb343-14" aria-hidden="true" tabindex="-1"></a>sotu_dtm <span class="ot">&lt;-</span> sotu_clean <span class="sc">%&gt;%</span> </span>
<span id="cb343-15"><a href="day5.html#cb343-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_length</span>(token) <span class="sc">&gt;</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb343-16"><a href="day5.html#cb343-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(year, token) <span class="sc">%&gt;%</span> </span>
<span id="cb343-17"><a href="day5.html#cb343-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">#filter(between(year, 1900, 2000)) %&gt;% </span></span>
<span id="cb343-18"><a href="day5.html#cb343-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(token) <span class="sc">%&gt;%</span> </span>
<span id="cb343-19"><a href="day5.html#cb343-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">n</span>() <span class="sc">&lt;</span> <span class="dv">95</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb343-20"><a href="day5.html#cb343-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cast_dtm</span>(<span class="at">document =</span> year, <span class="at">term =</span> token, <span class="at">value =</span> n)</span></code></pre></div>
<p>A DTM contains Documents (rows) and Terms (columns) and specifies how often a term appears in a document.</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="day5.html#cb344-1" aria-hidden="true" tabindex="-1"></a>sotu_dtm <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span> .[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span></code></pre></div>
<pre><code>##       Terms
## Docs   abandon abat abettor abey abid
##   1900       1    3       1    2    1
##   1901       2    0       0    0    4
##   1902       3    0       0    0    0
##   1903       3    1       0    0    0
##   1904       1    0       0    1    0</code></pre>
</div>
<div id="inferring-the-number-of-topics" class="section level3 hasAnchor" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Inferring the number of topics<a href="day5.html#inferring-the-number-of-topics" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We need to tell the model in advance how many topics we assume to be present within the document. Since we have neither read all the SOTU addresses (if so, we would hardly need to use the topic model), we cannot make an educated guess on how many topics are in there.</p>
<div id="making-guesses" class="section level4 hasAnchor" number="5.7.2.1">
<h4><span class="header-section-number">5.7.2.1</span> Making guesses<a href="day5.html#making-guesses" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>One approach might be to just provide it with wild guesses on how many topics might be in there and then try to make sense of them afterward.</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="day5.html#cb346-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(topicmodels)</span>
<span id="cb346-2"><a href="day5.html#cb346-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb346-3"><a href="day5.html#cb346-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb346-4"><a href="day5.html#cb346-4" aria-hidden="true" tabindex="-1"></a>sotu_lda_k10 <span class="ot">&lt;-</span> <span class="fu">LDA</span>(sotu_dtm, <span class="at">k =</span> <span class="dv">10</span>, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">seed =</span> <span class="dv">123</span>))</span>
<span id="cb346-5"><a href="day5.html#cb346-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb346-6"><a href="day5.html#cb346-6" aria-hidden="true" tabindex="-1"></a>sotu_lda_k10_tidied <span class="ot">&lt;-</span> <span class="fu">tidy</span>(sotu_lda_k10)</span></code></pre></div>
<p>The <code>tidy()</code> function from the <code>broom</code> package <span class="citation">(<a href="#ref-robinson_broom_2020" role="doc-biblioref">Robinson 2020</a>)</span> brings the LDA output back into a tidy format. It consists of three columns: the topic, the term, and <code>beta</code>, which is the probability that the term stems from this topic.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="day5.html#cb347-1" aria-hidden="true" tabindex="-1"></a>sotu_lda_k10_tidied <span class="sc">%&gt;%</span> <span class="fu">glimpse</span>()</span></code></pre></div>
<pre><code>## Rows: 108,880
## Columns: 3
## $ topic &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1,…
## $ term  &lt;chr&gt; &quot;abandon&quot;, &quot;abandon&quot;, &quot;abandon&quot;, &quot;abandon&quot;, &quot;abandon&quot;, &quot;abandon&quot;…
## $ beta  &lt;dbl&gt; 1.998668e-04, 2.063569e-04, 5.149531e-04, 3.737819e-04, 3.002458…</code></pre>
<p>Now, we can wrangle it a bit, and then visualize it with <code>ggplot2</code>.</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="day5.html#cb349-1" aria-hidden="true" tabindex="-1"></a>top_terms_k10 <span class="ot">&lt;-</span> sotu_lda_k10_tidied <span class="sc">%&gt;%</span></span>
<span id="cb349-2"><a href="day5.html#cb349-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(topic) <span class="sc">%&gt;%</span></span>
<span id="cb349-3"><a href="day5.html#cb349-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(beta, <span class="at">n =</span> <span class="dv">5</span>, <span class="at">with_ties =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb349-4"><a href="day5.html#cb349-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb349-5"><a href="day5.html#cb349-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(topic, <span class="sc">-</span>beta)</span>
<span id="cb349-6"><a href="day5.html#cb349-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb349-7"><a href="day5.html#cb349-7" aria-hidden="true" tabindex="-1"></a>top_terms_k10 <span class="sc">%&gt;%</span></span>
<span id="cb349-8"><a href="day5.html#cb349-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">topic =</span> <span class="fu">factor</span>(topic),</span>
<span id="cb349-9"><a href="day5.html#cb349-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">term =</span> <span class="fu">reorder_within</span>(term, beta, topic)) <span class="sc">%&gt;%</span></span>
<span id="cb349-10"><a href="day5.html#cb349-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(term, beta, <span class="at">fill =</span> topic)) <span class="sc">+</span></span>
<span id="cb349-11"><a href="day5.html#cb349-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb349-12"><a href="day5.html#cb349-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_reordered</span>() <span class="sc">+</span></span>
<span id="cb349-13"><a href="day5.html#cb349-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>topic, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>, <span class="at">ncol =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb349-14"><a href="day5.html#cb349-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-193-1.png" width="672" /></p>
<p>Now the hard part begins: inductively making sense of it. But, of course, there is a large probability that we just chose the wrong number of topics. Therefore, before scratching our heads trying to come to meaningful conclusions, we should first assess what the optimal number of topics is.</p>
</div>
<div id="more-elaborate-methods" class="section level4 hasAnchor" number="5.7.2.2">
<h4><span class="header-section-number">5.7.2.2</span> More elaborate methods<a href="day5.html#more-elaborate-methods" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>LDA offers a couple of parameters to tune, but the most crucial one probably is <code>k</code>, the number of topics.</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="day5.html#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ldatuning)</span></code></pre></div>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="day5.html#cb351-1" aria-hidden="true" tabindex="-1"></a>determine_k <span class="ot">&lt;-</span> <span class="fu">FindTopicsNumber</span>(</span>
<span id="cb351-2"><a href="day5.html#cb351-2" aria-hidden="true" tabindex="-1"></a>  sotu_dtm,</span>
<span id="cb351-3"><a href="day5.html#cb351-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">topics =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">2</span>, <span class="at">to =</span> <span class="dv">30</span>, <span class="at">by =</span> <span class="dv">1</span>),</span>
<span id="cb351-4"><a href="day5.html#cb351-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">&quot;Griffiths2004&quot;</span>, <span class="st">&quot;CaoJuan2009&quot;</span>, <span class="st">&quot;Arun2010&quot;</span>, <span class="st">&quot;Deveaud2014&quot;</span>),</span>
<span id="cb351-5"><a href="day5.html#cb351-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;Gibbs&quot;</span>,</span>
<span id="cb351-6"><a href="day5.html#cb351-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">list</span>(<span class="at">seed =</span> <span class="dv">77</span>),</span>
<span id="cb351-7"><a href="day5.html#cb351-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">mc.cores =</span> 16L,</span>
<span id="cb351-8"><a href="day5.html#cb351-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="cn">TRUE</span></span>
<span id="cb351-9"><a href="day5.html#cb351-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb351-10"><a href="day5.html#cb351-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-11"><a href="day5.html#cb351-11" aria-hidden="true" tabindex="-1"></a>determine_k <span class="sc">%&gt;%</span> <span class="fu">write_rds</span>(<span class="st">&quot;lda_tuning.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="day5.html#cb352-1" aria-hidden="true" tabindex="-1"></a><span class="fu">FindTopicsNumber_plot</span>(determine_k)</span></code></pre></div>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-197-1.png" width="672" /></p>
<p>We would go with the 16 topics here, as they seem to maximize the metrics that shall be maximized and minimizes the other ones quite well.</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="day5.html#cb354-1" aria-hidden="true" tabindex="-1"></a>sotu_lda_k16 <span class="ot">&lt;-</span> <span class="fu">LDA</span>(sotu_dtm, <span class="at">k =</span> <span class="dv">16</span>, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">seed =</span> <span class="dv">77</span>))</span>
<span id="cb354-2"><a href="day5.html#cb354-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb354-3"><a href="day5.html#cb354-3" aria-hidden="true" tabindex="-1"></a>sotu_lda_k16_tidied <span class="ot">&lt;-</span> <span class="fu">tidy</span>(sotu_lda_k16)</span>
<span id="cb354-4"><a href="day5.html#cb354-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb354-5"><a href="day5.html#cb354-5" aria-hidden="true" tabindex="-1"></a><span class="fu">write_rds</span>(sotu_lda_k16, <span class="st">&quot;lda_16.rds&quot;</span>)</span></code></pre></div>
</div>
</div>
<div id="sense-making" class="section level3 hasAnchor" number="5.7.3">
<h3><span class="header-section-number">5.7.3</span> Sense-making<a href="day5.html#sense-making" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, the harder part begins: making sense of the different topics. In LDA, words can exist across topics, making them not perfectly distinguishable. Also, as the number of topics becomes greater, plotting them doesn’t make too much sense anymore.</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="day5.html#cb355-1" aria-hidden="true" tabindex="-1"></a>topic_list <span class="ot">&lt;-</span> sotu_lda_k16_tidied <span class="sc">%&gt;%</span> </span>
<span id="cb355-2"><a href="day5.html#cb355-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(topic) <span class="sc">%&gt;%</span> </span>
<span id="cb355-3"><a href="day5.html#cb355-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_split</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb355-4"><a href="day5.html#cb355-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map_dfc</span>(<span class="sc">~</span>.x <span class="sc">%&gt;%</span> </span>
<span id="cb355-5"><a href="day5.html#cb355-5" aria-hidden="true" tabindex="-1"></a>            <span class="fu">slice_max</span>(beta, <span class="at">n =</span> <span class="dv">20</span>, <span class="at">with_ties =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb355-6"><a href="day5.html#cb355-6" aria-hidden="true" tabindex="-1"></a>            <span class="fu">arrange</span>(<span class="sc">-</span>beta) <span class="sc">%&gt;%</span> </span>
<span id="cb355-7"><a href="day5.html#cb355-7" aria-hidden="true" tabindex="-1"></a>            <span class="fu">select</span>(term)) <span class="sc">%&gt;%</span> </span>
<span id="cb355-8"><a href="day5.html#cb355-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_names</span>(<span class="fu">str_c</span>(<span class="st">&quot;topic&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">16</span>, <span class="at">sep =</span> <span class="st">&quot;_&quot;</span>))</span></code></pre></div>
<pre><code>## New names:
## • `term` -&gt; `term...1`
## • `term` -&gt; `term...2`
## • `term` -&gt; `term...3`
## • `term` -&gt; `term...4`
## • `term` -&gt; `term...5`
## • `term` -&gt; `term...6`
## • `term` -&gt; `term...7`
## • `term` -&gt; `term...8`
## • `term` -&gt; `term...9`
## • `term` -&gt; `term...10`
## • `term` -&gt; `term...11`
## • `term` -&gt; `term...12`
## • `term` -&gt; `term...13`
## • `term` -&gt; `term...14`
## • `term` -&gt; `term...15`
## • `term` -&gt; `term...16`</code></pre>
</div>
<div id="document-topic-probabilities" class="section level3 hasAnchor" number="5.7.4">
<h3><span class="header-section-number">5.7.4</span> Document-topic probabilities<a href="day5.html#document-topic-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another thing to assess is document-topic probabilities <code>gamma</code>: which document belongs to which topic. By doing so, you can choose the documents that have the highest probability of belonging to a topic and then read these specifically. This might give you a better understanding of what the different topics might imply.</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="day5.html#cb357-1" aria-hidden="true" tabindex="-1"></a>sotu_lda_k16_document <span class="ot">&lt;-</span> <span class="fu">tidy</span>(sotu_lda_k16, <span class="at">matrix =</span> <span class="st">&quot;gamma&quot;</span>)</span></code></pre></div>
<p>This shows you the proportion of words in the document which were drawn from the specific topics. In 1990, for instance, many words were drawn from the first topic.</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="day5.html#cb358-1" aria-hidden="true" tabindex="-1"></a>sotu_lda_k16_document <span class="sc">%&gt;%</span> </span>
<span id="cb358-2"><a href="day5.html#cb358-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(document) <span class="sc">%&gt;%</span> </span>
<span id="cb358-3"><a href="day5.html#cb358-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(gamma, <span class="at">n =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb358-4"><a href="day5.html#cb358-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">gamma =</span> <span class="fu">round</span>(gamma, <span class="dv">3</span>))</span></code></pre></div>
<pre><code>## # A tibble: 99 × 3
## # Groups:   document [99]
##    document topic gamma
##    &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;
##  1 1900        13 1    
##  2 1901         2 1    
##  3 1902         2 0.997
##  4 1903         8 0.72 
##  5 1904         8 0.727
##  6 1905         8 0.998
##  7 1906         8 0.973
##  8 1907         2 0.817
##  9 1908         8 0.613
## 10 1909        11 1    
## # … with 89 more rows</code></pre>
<p>An interesting pattern is that the topics show some time-dependency. This intuitively makes sense, as they might represent some sort of deeper underlying issue.</p>
<div id="ldavis" class="section level4 hasAnchor" number="5.7.4.1">
<h4><span class="header-section-number">5.7.4.1</span> <code>LDAvis</code><a href="day5.html#ldavis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><code>LDAvis</code> is a handy tool we can use to inspect our model visually. Preprocessing the data is a bit tricky though, therefore we define a quick function first.</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="day5.html#cb360-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(LDAvis)</span>
<span id="cb360-2"><a href="day5.html#cb360-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb360-3"><a href="day5.html#cb360-3" aria-hidden="true" tabindex="-1"></a>prep_lda_output <span class="ot">&lt;-</span> <span class="cf">function</span>(dtm, lda_output){</span>
<span id="cb360-4"><a href="day5.html#cb360-4" aria-hidden="true" tabindex="-1"></a>  doc_length <span class="ot">&lt;-</span> dtm <span class="sc">%&gt;%</span> </span>
<span id="cb360-5"><a href="day5.html#cb360-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb360-6"><a href="day5.html#cb360-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb360-7"><a href="day5.html#cb360-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rowwise</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb360-8"><a href="day5.html#cb360-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">doc_sum =</span> <span class="fu">c_across</span>() <span class="sc">%&gt;%</span> <span class="fu">sum</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb360-9"><a href="day5.html#cb360-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pull</span>(doc_sum)</span>
<span id="cb360-10"><a href="day5.html#cb360-10" aria-hidden="true" tabindex="-1"></a>  phi <span class="ot">&lt;-</span> <span class="fu">posterior</span>(lda_output)<span class="sc">$</span>terms <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb360-11"><a href="day5.html#cb360-11" aria-hidden="true" tabindex="-1"></a>  theta <span class="ot">&lt;-</span> <span class="fu">posterior</span>(lda_output)<span class="sc">$</span>topics <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb360-12"><a href="day5.html#cb360-12" aria-hidden="true" tabindex="-1"></a>  vocab <span class="ot">&lt;-</span> <span class="fu">colnames</span>(dtm)</span>
<span id="cb360-13"><a href="day5.html#cb360-13" aria-hidden="true" tabindex="-1"></a>  term_sums <span class="ot">&lt;-</span> dtm <span class="sc">%&gt;%</span> </span>
<span id="cb360-14"><a href="day5.html#cb360-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb360-15"><a href="day5.html#cb360-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb360-16"><a href="day5.html#cb360-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="sc">~</span><span class="fu">sum</span>(.x))) <span class="sc">%&gt;%</span> </span>
<span id="cb360-17"><a href="day5.html#cb360-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>()</span>
<span id="cb360-18"><a href="day5.html#cb360-18" aria-hidden="true" tabindex="-1"></a>  svd_tsne <span class="ot">&lt;-</span> <span class="cf">function</span>(x) tsne<span class="sc">::</span><span class="fu">tsne</span>(<span class="fu">svd</span>(x)<span class="sc">$</span>u)</span>
<span id="cb360-19"><a href="day5.html#cb360-19" aria-hidden="true" tabindex="-1"></a>  LDAvis<span class="sc">::</span><span class="fu">createJSON</span>(<span class="at">phi =</span> phi, </span>
<span id="cb360-20"><a href="day5.html#cb360-20" aria-hidden="true" tabindex="-1"></a>                     <span class="at">theta =</span> theta,</span>
<span id="cb360-21"><a href="day5.html#cb360-21" aria-hidden="true" tabindex="-1"></a>                     <span class="at">vocab =</span> vocab,</span>
<span id="cb360-22"><a href="day5.html#cb360-22" aria-hidden="true" tabindex="-1"></a>                     <span class="at">doc.length =</span> doc_length,</span>
<span id="cb360-23"><a href="day5.html#cb360-23" aria-hidden="true" tabindex="-1"></a>                     <span class="at">term.frequency =</span> term_sums[<span class="dv">1</span>,],</span>
<span id="cb360-24"><a href="day5.html#cb360-24" aria-hidden="true" tabindex="-1"></a>                     <span class="at">mds.method =</span> svd_tsne</span>
<span id="cb360-25"><a href="day5.html#cb360-25" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb360-26"><a href="day5.html#cb360-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb360-27"><a href="day5.html#cb360-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb360-28"><a href="day5.html#cb360-28" aria-hidden="true" tabindex="-1"></a>json_lda <span class="ot">&lt;-</span> <span class="fu">prep_lda_output</span>(sotu_dtm, sotu_lda_k16)</span></code></pre></div>
<pre><code>## sigma summary: Min. : 33554432 |1st Qu. : 33554432 |Median : 33554432 |Mean : 33554432 |3rd Qu. : 33554432 |Max. : 33554432 |</code></pre>
<pre><code>## Epoch: Iteration #100 error is: 12.1436251490033</code></pre>
<pre><code>## Epoch: Iteration #200 error is: 0.525550510030935</code></pre>
<pre><code>## Epoch: Iteration #300 error is: 0.371666187469788</code></pre>
<pre><code>## Epoch: Iteration #400 error is: 0.364478824976636</code></pre>
<pre><code>## Epoch: Iteration #500 error is: 0.361477882099313</code></pre>
<pre><code>## Epoch: Iteration #600 error is: 0.358900276265406</code></pre>
<pre><code>## Epoch: Iteration #700 error is: 0.358157600067434</code></pre>
<pre><code>## Epoch: Iteration #800 error is: 0.357548799328358</code></pre>
<pre><code>## Epoch: Iteration #900 error is: 0.357274746683993</code></pre>
<pre><code>## Epoch: Iteration #1000 error is: 0.357073805574637</code></pre>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="day5.html#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="fu">serVis</span>(json_lda, <span class="at">out.dir =</span> <span class="st">&#39;vis&#39;</span>, <span class="at">open.browser =</span> <span class="cn">TRUE</span>)</span>
<span id="cb372-2"><a href="day5.html#cb372-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb372-3"><a href="day5.html#cb372-3" aria-hidden="true" tabindex="-1"></a>servr<span class="sc">::</span><span class="fu">daemon_stop</span>(<span class="dv">1</span>)</span></code></pre></div>
</div>
</div>
<div id="structural-topic-models" class="section level3 hasAnchor" number="5.7.5">
<h3><span class="header-section-number">5.7.5</span> Structural Topic Models<a href="day5.html#structural-topic-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Structural Topic Models offer a framework for incorporating metadata into topic models. In particular, you can have these metadata affect the <em>topical prevalence</em>, i.e., the frequency a certain <em>topic</em> is discussed can vary depending on some observed non-textual property of the document. On the other hand, the topical content, i.e., the terms that constitute topics, may vary depending on certain covariates.</p>
<p>Structural Topic Models are implemented in R via a dedicated package. The following overview provides information on the workflow and the functions that facilitate it.</p>
<p><img src="https://warin.ca/shiny/stm/images/fig02.png" alt="Roberts, Stewart, and Tingley (2019)" />
In the following example, I will use the State of the Union addresses to run you through the process of training and evaluating an STM.</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="day5.html#cb373-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stm)</span></code></pre></div>
<pre><code>## stm v1.3.6 successfully loaded. See ?stm for help. 
##  Papers, resources, and other materials at structuraltopicmodel.com</code></pre>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="day5.html#cb375-1" aria-hidden="true" tabindex="-1"></a>sotu_stm <span class="ot">&lt;-</span> sotu_meta <span class="sc">%&gt;%</span> </span>
<span id="cb375-2"><a href="day5.html#cb375-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">text =</span> sotu_text) <span class="sc">%&gt;%</span> </span>
<span id="cb375-3"><a href="day5.html#cb375-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(text, <span class="at">.keep_all =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb375-4"><a href="day5.html#cb375-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">between</span>(year, <span class="dv">1900</span>, <span class="dv">2000</span>))</span></code></pre></div>
<p>The package requires a particular data structure and has included several functions that help you preprocess your data. <code>textProcessor()</code> takes care of preprocessing the data. It takes as a first argument the text as a character vector as well as the tibble containing the metadata. Its output is a list containing a document list containing word indices and counts, a vocabulary vector containing words associated with these word indices, and a data.frame containing associated metadata. <code>prepDocuments()</code> finally brings the resulting list into a shape that is appropriate for training an STM. It has certain threshold parameters which are geared towards further reducing the vocabulary. <code>lower.thresh = n</code> removes words that are not present in at least n documents, <code>upper.thresh = m</code> removes words that are present in more than m documents. The ramifications of these parameter settings can be explored graphically using the <code>plotRemoved()</code> function.</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="day5.html#cb376-1" aria-hidden="true" tabindex="-1"></a>processed <span class="ot">&lt;-</span> <span class="fu">textProcessor</span>(sotu_stm<span class="sc">$</span>text, <span class="at">metadata =</span> sotu_stm <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>text))</span></code></pre></div>
<pre><code>## Building corpus... 
## Converting to Lower Case... 
## Removing punctuation... 
## Removing stopwords... 
## Removing numbers... 
## Stemming... 
## Creating Output...</code></pre>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="day5.html#cb378-1" aria-hidden="true" tabindex="-1"></a><span class="co">#, custompunctuation = &quot;-&quot;)</span></span>
<span id="cb378-2"><a href="day5.html#cb378-2" aria-hidden="true" tabindex="-1"></a><span class="co">#?textProcessor() # check out the different arguments </span></span>
<span id="cb378-3"><a href="day5.html#cb378-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb378-4"><a href="day5.html#cb378-4" aria-hidden="true" tabindex="-1"></a><span class="co">#?prepDocuments()</span></span>
<span id="cb378-5"><a href="day5.html#cb378-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb378-6"><a href="day5.html#cb378-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plotRemoved</span>(processed<span class="sc">$</span>documents, <span class="at">lower.thresh =</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">50</span>, <span class="at">by =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-206-1.png" width="672" /></p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="day5.html#cb379-1" aria-hidden="true" tabindex="-1"></a>prepped_docs <span class="ot">&lt;-</span> <span class="fu">prepDocuments</span>(processed<span class="sc">$</span>documents, processed<span class="sc">$</span>vocab, processed<span class="sc">$</span>meta, <span class="at">lower.thresh =</span> <span class="dv">3</span>, <span class="at">upper.thresh =</span> <span class="dv">80</span>)</span></code></pre></div>
<pre><code>## Removing 9638 of 14346 terms (43586 of 136130 tokens) due to frequency 
## Your corpus now has 109 documents, 4708 terms and 92544 tokens.</code></pre>
<p>Now that the data is properly preprocessed and prepared, we can estimate the actual model. As mentioned before, covariates can influence topical prevalence as well as their content. I assume topical prevalence to be influenced by the party of the speaker as well as the year the SOTU was held. The latter is assumed to influence the topical prevalence in a non-linear way (SOTU addresses usually deal with acute topics which do not gradually build over time) and is therefore estimated with a spline through the <code>s()</code> function that comes from the <code>stm</code> package. It defaults to a spline with 10 degrees of freedom. Moreover, I assume the content of topics to be influenced by party affiliation. Both <code>prevalence =</code> and <code>content =</code> take their arguments in formula notation.</p>
<p>As determined before, I assume the presence of <code>K = 16</code> topics (<code>stm</code> also offers the <code>searchK()</code> function to tune this hyperparameter)</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="day5.html#cb381-1" aria-hidden="true" tabindex="-1"></a>sotu_content_fit <span class="ot">&lt;-</span> <span class="fu">stm</span>(<span class="at">documents =</span> prepped_docs<span class="sc">$</span>documents, </span>
<span id="cb381-2"><a href="day5.html#cb381-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">vocab =</span> prepped_docs<span class="sc">$</span>vocab, </span>
<span id="cb381-3"><a href="day5.html#cb381-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">K =</span> <span class="dv">16</span>, </span>
<span id="cb381-4"><a href="day5.html#cb381-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">prevalence =</span> <span class="sc">~</span>party <span class="sc">+</span> <span class="fu">s</span>(year),</span>
<span id="cb381-5"><a href="day5.html#cb381-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">content =</span> <span class="sc">~</span>party,</span>
<span id="cb381-6"><a href="day5.html#cb381-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">max.em.its =</span> <span class="dv">75</span>, </span>
<span id="cb381-7"><a href="day5.html#cb381-7" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data =</span> prepped_docs<span class="sc">$</span>meta, </span>
<span id="cb381-8"><a href="day5.html#cb381-8" aria-hidden="true" tabindex="-1"></a>                        <span class="at">init.type =</span> <span class="st">&quot;Spectral&quot;</span>,</span>
<span id="cb381-9"><a href="day5.html#cb381-9" aria-hidden="true" tabindex="-1"></a>                        <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>Let’s look at a summary of the topics and their prevalence. For this, we can use a <a href="https://github.com/cschwem2er/stminsights">shiny app developed by Carsten Schwemmer</a></p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="day5.html#cb382-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stminsights)</span>
<span id="cb382-2"><a href="day5.html#cb382-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb382-3"><a href="day5.html#cb382-3" aria-hidden="true" tabindex="-1"></a>prepped_docs<span class="sc">$</span>meta<span class="sc">$</span>party <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(prepped_docs<span class="sc">$</span>meta<span class="sc">$</span>party)</span>
<span id="cb382-4"><a href="day5.html#cb382-4" aria-hidden="true" tabindex="-1"></a>prep <span class="ot">&lt;-</span> <span class="fu">estimateEffect</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">16</span> <span class="sc">~</span> party <span class="sc">+</span> <span class="fu">s</span>(year), sotu_content_fit, <span class="at">meta =</span> prepped_docs<span class="sc">$</span>meta, <span class="at">uncertainty =</span> <span class="st">&quot;Global&quot;</span>)</span>
<span id="cb382-5"><a href="day5.html#cb382-5" aria-hidden="true" tabindex="-1"></a><span class="fu">map</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">16</span>, <span class="sc">~</span><span class="fu">summary</span>(prep, <span class="at">topics =</span> .x))</span>
<span id="cb382-6"><a href="day5.html#cb382-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb382-7"><a href="day5.html#cb382-7" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(prepped_docs, sotu_stm, prep, <span class="at">file =</span> <span class="st">&quot;stm_insights.RData&quot;</span>)</span>
<span id="cb382-8"><a href="day5.html#cb382-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb382-9"><a href="day5.html#cb382-9" aria-hidden="true" tabindex="-1"></a><span class="fu">run_stminsights</span>()</span></code></pre></div>
</div>
</div>
<div id="further-readings" class="section level2 hasAnchor" number="5.8">
<h2><span class="header-section-number">5.8</span> Further readings<a href="day5.html#further-readings" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Check out the <a href="https://smltar.com">SMLTAR book</a></li>
<li>More on <a href="https://www.tidymodels.org">tidymodels</a></li>
<li>Basic <a href="https://www.simplilearn.com/10-algorithms-machine-learning-engineers-need-to-know-article">descriptions of ML models</a></li>
<li>More on prediction with text using <a href="https://www.tidymodels.org/learn/work/tune-text/">tidymodels</a></li>
<li>A <code>shiny</code> <a href="https://warin.ca/shiny/stm/#section-the-structural-topic-model">introduction to STM</a> by Thierry Warin</li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-grun_topicmodels_2020" class="csl-entry">
Grün, Bettina, Kurt Hornik, David Blei, John Lafferty, Xuan-Hieu Phan, Makoto Matsumoto, Nishimura Takuji, and Shawn Cokus. 2020. <span>“Topicmodels: <span>Topic Models</span>.”</span>
</div>
<div id="ref-hvitfeldt_textrecipes_2022" class="csl-entry">
Hvitfeldt, Emil. 2022. <span>“Textrecipes: <span>Extra</span> ’<span>Recipes</span>’ for <span>Text Processing</span>.”</span>
</div>
<div id="ref-kuhn_dials_2022" class="csl-entry">
Kuhn, Max, and Hannah Frick. 2022. <span>“Dials: <span>Tools</span> for <span>Creating Tuning Parameter Values</span>.”</span>
</div>
<div id="ref-kuhn_parsnip_2022" class="csl-entry">
Kuhn, Max, Davis Vaughan, and Emil Hvitfeldt. 2022. <span>“Parsnip: <span>A Common API</span> to <span>Modeling</span> and <span>Analysis Functions</span>.”</span>
</div>
<div id="ref-kuhn_tidymodels_2020" class="csl-entry">
Kuhn, Max, and Hadley Wickham. 2020. <span>“Tidymodels: A Collection of Packages for Modeling and Machine Learning Using Tidyverse Principles.”</span>
</div>
<div id="ref-kuhn_recipes_2022" class="csl-entry">
———. 2022. <span>“Recipes: <span>Preprocessing</span> and <span>Feature Engineering Steps</span> for <span>Modeling</span>.”</span>
</div>
<div id="ref-robinson_broom_2020" class="csl-entry">
Robinson, David. 2020. <span>“Broom: <span>Convert Statistical Analysis Objects</span> into <span>Tidy Data Frames</span>.”</span>
</div>
<div id="ref-vaughan_workflows_2022" class="csl-entry">
Vaughan, Davis. 2022. <span>“Workflows: <span>Modeling Workflows</span>.”</span>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="day4.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="day6.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/04-ml.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
